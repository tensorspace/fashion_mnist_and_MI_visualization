{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "import loggingreporter \n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "cfg = {}\n",
    "cfg['SGD_BATCHSIZE']    = 128\n",
    "cfg['SGD_LEARNINGRATE'] = 0.001\n",
    "cfg['NUM_EPOCHS']       = 20\n",
    "\n",
    "cfg['ACTIVATION'] = 'relu'\n",
    "#cfg['ACTIVATION'] = 'tanh'\n",
    "# How many hidden neurons to put into each of the layers\n",
    "cfg['LAYER_DIMS'] = [1024, 20, 20, 20]\n",
    "#cfg['LAYER_DIMS'] = [32, 28, 24, 20, 16, 12, 8, 8]\n",
    "#cfg['LAYER_DIMS'] = [128, 64, 32, 16, 16] # 0.967 w. 128\n",
    "#cfg['LAYER_DIMS'] = [20, 20, 20, 20, 20, 20] # 0.967 w. 128\n",
    "#ARCH_NAME =  '-'.join(map(str,cfg['LAYER_DIMS']))\n",
    "ARCH_NAME = 'simple_CNN'\n",
    "# trn, tst = utils.get_mnist()\n",
    "nb_classes = 10\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train = np.reshape(X_train, [X_train.shape[0], 28, 28, 1]).astype('float32') / 255.\n",
    "X_test  = np.reshape(X_test , [X_test.shape[0] , 28, 28, 1]).astype('float32') / 255.\n",
    "Y_train = keras.utils.np_utils.to_categorical(y_train, nb_classes).astype('float32')\n",
    "Y_test  = keras.utils.np_utils.to_categorical(y_test, nb_classes).astype('float32')\n",
    "\n",
    "Dataset = namedtuple('Dataset',['X','Y','y','nb_classes'])\n",
    "trn = Dataset(X_train, Y_train, y_train, nb_classes)\n",
    "tst = Dataset(X_test , Y_test, y_test, nb_classes)\n",
    "# Where to save activation and weights data\n",
    "cfg['SAVE_DIR'] = 'rawdata/' + cfg['ACTIVATION'] + '_' + ARCH_NAME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_layer  = keras.layers.Input((trn.X.shape[1],))\n",
    "#clayer = input_layer\n",
    "#for n in cfg['LAYER_DIMS']:\n",
    "#    clayer = keras.layers.Dense(n, activation=cfg['ACTIVATION'])(clayer)\n",
    "#output_layer = keras.layers.Dense(trn.nb_classes, activation='softmax')(clayer)\n",
    "\n",
    "#model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "#optimizer = keras.optimizers.SGD(lr=cfg['SGD_LEARNINGRATE'])\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "cnn1 = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=[28, 28, 1]),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "cnn1.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                100384    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 100,874\n",
      "Trainable params: 100,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "model3=Sequential()\n",
    "model3.add(Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\", \n",
    "          input_shape=X_train.shape[1:], activation='relu'))\n",
    "#model3.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Dropout(0.5))\n",
    "#model3.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation='relu'))\n",
    "#model3.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"valid\", activation='relu'))\n",
    "#model3.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "#model3.add(Dropout(0.5))\n",
    "model3.add(Flatten())\n",
    "#model3.add(Dense(256))\n",
    "#model3.add(LeakyReLU())\n",
    "#model3.add(Dropout(0.5))\n",
    "model3.add(Dense(32))\n",
    "#model3.add(LeakyReLU())\n",
    "#model2.add(Dropout(0.5))\n",
    "model3.add(Dense(num_classes, activation='softmax'))\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 1664/60000 [..............................] - ETA: 18s - loss: 1.6801 - acc: 0.4387"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/keras/callbacks.py:97: UserWarning: Method on_batch_begin() is slow compared to the batch update (0.130404). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.5660 - acc: 0.7970\n",
      "Saving rawdata/relu_simple_CNN/epoch00000000\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.4117 - acc: 0.8536\n",
      "Saving rawdata/relu_simple_CNN/epoch00000001\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3782 - acc: 0.8668\n",
      "Saving rawdata/relu_simple_CNN/epoch00000002\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3584 - acc: 0.8726\n",
      "Saving rawdata/relu_simple_CNN/epoch00000003\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.3451 - acc: 0.8771\n",
      "Saving rawdata/relu_simple_CNN/epoch00000004\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3346 - acc: 0.8810\n",
      "Saving rawdata/relu_simple_CNN/epoch00000005\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3234 - acc: 0.8847\n",
      "Saving rawdata/relu_simple_CNN/epoch00000006\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3188 - acc: 0.8851\n",
      "Saving rawdata/relu_simple_CNN/epoch00000007\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.3131 - acc: 0.8879\n",
      "Saving rawdata/relu_simple_CNN/epoch00000008\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3100 - acc: 0.8891\n",
      "Saving rawdata/relu_simple_CNN/epoch00000009\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3058 - acc: 0.8916\n",
      "Saving rawdata/relu_simple_CNN/epoch00000010\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3011 - acc: 0.8918\n",
      "Saving rawdata/relu_simple_CNN/epoch00000011\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.2954 - acc: 0.8931\n",
      "Saving rawdata/relu_simple_CNN/epoch00000012\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.2944 - acc: 0.8943\n",
      "Saving rawdata/relu_simple_CNN/epoch00000013\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.2930 - acc: 0.8943\n",
      "Saving rawdata/relu_simple_CNN/epoch00000014\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.2899 - acc: 0.8954\n",
      "Saving rawdata/relu_simple_CNN/epoch00000015\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.2863 - acc: 0.8968\n",
      "Saving rawdata/relu_simple_CNN/epoch00000016\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.2871 - acc: 0.8960\n",
      "Saving rawdata/relu_simple_CNN/epoch00000017\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.2839 - acc: 0.8975\n",
      "Saving rawdata/relu_simple_CNN/epoch00000018\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.2809 - acc: 0.8988\n",
      "Saving rawdata/relu_simple_CNN/epoch00000019\n"
     ]
    }
   ],
   "source": [
    "def do_report(epoch):\n",
    "    # Only log activity for some epochs.  Mainly this is to make things run faster.\n",
    "    if epoch < 20:       # Log for all first 20 epochs\n",
    "        return True\n",
    "    elif epoch < 100:    # Then for every 5th epoch\n",
    "        return (epoch % 5 == 0)\n",
    "    elif epoch < 200:    # Then every 10th\n",
    "        return (epoch % 10 == 0)\n",
    "    else:                # Then every 100th\n",
    "        return (epoch % 100 == 0)\n",
    "    \n",
    "reporter = loggingreporter.LoggingReporter(cfg=cfg, \n",
    "                                          trn=trn, \n",
    "                                          tst=tst, \n",
    "                                          do_save_func=do_report)\n",
    "r = model3.fit(x=trn.X, y=trn.Y, \n",
    "              verbose    = 1, \n",
    "              batch_size = cfg['SGD_BATCHSIZE'],\n",
    "              epochs     = cfg['NUM_EPOCHS'],\n",
    "              # validation_data=(tst.X, tst.Y),\n",
    "              callbacks  = [reporter,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test loss:', 0.2805305122733116)\n",
      "('Test accuracy:', 0.9022)\n"
     ]
    }
   ],
   "source": [
    "score = model3.evaluate(tst.X, tst.Y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
